#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†å²æ•°æ®å¯¼å…¥è„šæœ¬
ä»export_bsbdbfjfjff_all.txtæ–‡ä»¶ä¸­è¯»å–JSONæ ¼å¼çš„å†å²æ•°æ®å¹¶å¯¼å…¥åˆ°æ•°æ®åº“
"""

import json
import re
import time
from datetime import datetime
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from sqlalchemy.exc import OperationalError
from model import Message, Base
from config import settings

def extract_links_from_text(text: str) -> dict:
    """ä»æ–‡æœ¬ä¸­æå–ç½‘ç›˜é“¾æ¥"""
    links = {}
    
    # ç™¾åº¦ç½‘ç›˜é“¾æ¥æ¨¡å¼
    baidu_pattern = r'https://pan\.baidu\.com/s/[A-Za-z0-9_-]+(?:\?pwd=[A-Za-z0-9]+)?'
    baidu_matches = re.findall(baidu_pattern, text)
    for match in baidu_matches:
        links["ç™¾åº¦ç½‘ç›˜"] = match
    
    # å¤¸å…‹ç½‘ç›˜é“¾æ¥æ¨¡å¼
    quark_pattern = r'https://pan\.quark\.cn/s/[A-Za-z0-9_-]+'
    quark_matches = re.findall(quark_pattern, text)
    for match in quark_matches:
        links["å¤¸å…‹ç½‘ç›˜"] = match
    
    # é˜¿é‡Œäº‘ç›˜é“¾æ¥æ¨¡å¼
    aliyun_pattern = r'https://www\.aliyundrive\.com/s/[A-Za-z0-9_-]+'
    aliyun_matches = re.findall(aliyun_pattern, text)
    for match in aliyun_matches:
        links["é˜¿é‡Œäº‘ç›˜"] = match
    
    # 115ç½‘ç›˜é“¾æ¥æ¨¡å¼
    pan115_pattern = r'https://115\.com/s/[A-Za-z0-9_-]+'
    pan115_matches = re.findall(pan115_pattern, text)
    for match in pan115_matches:
        links["115ç½‘ç›˜"] = match
    
    # è¿…é›·ç½‘ç›˜é“¾æ¥æ¨¡å¼
    xunlei_pattern = r'https://pan\.xunlei\.com/s/[A-Za-z0-9_-]+(?:\?pwd=[A-Za-z0-9]+)?(?:#)?'
    xunlei_matches = re.findall(xunlei_pattern, text)
    for match in xunlei_matches:
        links["è¿…é›·ç½‘ç›˜"] = match
    
    # UCç½‘ç›˜é“¾æ¥æ¨¡å¼
    uc_pattern = r'https://drive\.uc\.cn/s/[A-Za-z0-9]+(?:\?public=1)?'
    uc_matches = re.findall(uc_pattern, text)
    for match in uc_matches:
        links["UCç½‘ç›˜"] = match
    
    # 123panç½‘ç›˜é“¾æ¥æ¨¡å¼
    pan123pan_pattern = r'https://www\.123pan\.com/s/[A-Za-z0-9_-]+(?:\?pwd=[A-Za-z0-9]+)?'
    pan123pan_matches = re.findall(pan123pan_pattern, text)
    if pan123pan_matches:
        links["123ç½‘ç›˜"] = pan123pan_matches[0]  # å–ç¬¬ä¸€ä¸ªåŒ¹é…
    
    # 123684ç½‘ç›˜é“¾æ¥æ¨¡å¼ï¼ˆ123ç½‘ç›˜æ–°åŸŸåï¼‰
    pan123684_pattern = r'https://www\.123684\.com/s/[A-Za-z0-9_-]+(?:\?pwd=[A-Za-z0-9]+)?'
    pan123684_matches = re.findall(pan123684_pattern, text)
    if pan123684_matches and "123ç½‘ç›˜" not in links:
        links["123ç½‘ç›˜"] = pan123684_matches[0]  # åªæœ‰åœ¨æ²¡æœ‰123pané“¾æ¥æ—¶æ‰ä½¿ç”¨123684é“¾æ¥
    
    # å¤©ç¿¼äº‘ç›˜é“¾æ¥æ¨¡å¼
    tianyi_pattern = r'https://cloud\.189\.cn/t/[A-Za-z0-9]+'
    tianyi_matches = re.findall(tianyi_pattern, text)
    for match in tianyi_matches:
        links["å¤©ç¿¼äº‘ç›˜"] = match
    
    # ç§»åŠ¨äº‘ç›˜é“¾æ¥æ¨¡å¼
    caiyun_pattern = r'https://caiyun\.139\.com/w/i/[A-Za-z0-9]+'
    caiyun_matches = re.findall(caiyun_pattern, text)
    for match in caiyun_matches:
        links["ç§»åŠ¨äº‘ç›˜"] = match
    
    return links

def extract_tags_from_text(text: str) -> list:
    """ä»æ–‡æœ¬ä¸­æå–æ ‡ç­¾"""
    # æå–#å¼€å¤´çš„æ ‡ç­¾
    tag_pattern = r'#([^\s#]+)'
    tags = re.findall(tag_pattern, text)
    return list(set(tags))  # å»é‡

def parse_historical_message(data: dict) -> dict:
    """è§£æå†å²æ¶ˆæ¯æ•°æ®"""
    text = data.get('text', '')
    
    # æå–é“¾æ¥
    links = extract_links_from_text(text)
    
    # å¦‚æœæ²¡æœ‰ç½‘ç›˜é“¾æ¥ï¼Œè·³è¿‡
    if not links:
        return None
    
    # æå–æ ‡ç­¾
    tags = extract_tags_from_text(text)
    
    # è§£ææ—¶é—´
    date_str = data.get('date', '')
    try:
        timestamp = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
    except:
        timestamp = datetime.utcnow()
    
    # æå–æ ‡é¢˜å’Œæè¿°
    lines = text.split('\n')
    title = ''
    description = ''
    
    # å¯»æ‰¾æ ‡é¢˜ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€è¡Œéç©ºè¡Œï¼‰
    for line in lines:
        line = line.strip()
        if line and not line.startswith('#') and not line.startswith('ğŸ”—'):
            if not title:
                title = line
            else:
                description += line + '\n'
    
    description = description.strip()
    
    return {
        'title': title,
        'description': description,
        'links': links,
        'tags': tags,
        'timestamp': timestamp,
        'source': 'historical_import',
        'channel': 'unknown',
        'group_name': None,
        'bot': None
    }

def upsert_historical_message(session, parsed_data: dict) -> str:
    """æ’å…¥æˆ–æ›´æ–°å†å²æ¶ˆæ¯"""
    if not parsed_data or not parsed_data.get('links'):
        return 'skipped'
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒé“¾æ¥çš„æ¶ˆæ¯
            existing = None
            for netdisk, link in parsed_data['links'].items():
                existing = session.query(Message).filter(
                    Message.links.op('->>')(netdisk) == link
                ).first()
                if existing:
                    break
            
            if existing:
                # æ›´æ–°ç°æœ‰æ¶ˆæ¯
                existing.title = parsed_data['title']
                existing.description = parsed_data['description']
                existing.tags = parsed_data['tags']
                existing.links = parsed_data['links']
                existing.timestamp = parsed_data['timestamp']
                session.commit()
                return 'updated'
            else:
                # æ’å…¥æ–°æ¶ˆæ¯
                new_msg = Message(
                    title=parsed_data['title'],
                    description=parsed_data['description'],
                    tags=parsed_data['tags'],
                    links=parsed_data['links'],
                    timestamp=parsed_data['timestamp'],
                    source=parsed_data['source'],
                    channel=parsed_data['channel'],
                    group_name=parsed_data['group_name'],
                    bot=parsed_data['bot']
                )
                session.add(new_msg)
                session.commit()
                return 'inserted'
        except OperationalError as e:
            print(f"âš ï¸ æ•°æ®åº“è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            session.rollback()
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                continue
            else:
                raise
        except Exception as e:
            print(f"âŒ æ•°æ®åº“æ“ä½œé”™è¯¯: {e}")
            session.rollback()
            return 'error'

def create_db_session_with_retry(max_retries=3):
    """åˆ›å»ºæ•°æ®åº“ä¼šè¯ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    for attempt in range(max_retries):
        try:
            engine = create_engine(settings.DATABASE_URL, pool_pre_ping=True, pool_recycle=3600)
            Base.metadata.create_all(bind=engine)
            SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
            session = SessionLocal()
            # æµ‹è¯•è¿æ¥
            session.execute(text('SELECT 1'))
            return session
        except OperationalError as e:
            print(f"âš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
                continue
            else:
                raise

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å¯¼å…¥å†å²æ•°æ®...")
    
    session = None
    try:
        # åˆ›å»ºæ•°æ®åº“è¿æ¥
        session = create_db_session_with_retry()
        
        # è¯»å–å†å²æ•°æ®æ–‡ä»¶
        file_path = '000.txt'
        print(f"ğŸ“ è¯»å–æ–‡ä»¶: {file_path}")
        
        total_lines = 0
        processed = 0
        inserted = 0
        updated = 0
        skipped = 0
        
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                total_lines += 1
                line = line.strip()
                
                if not line:
                    continue
                
                try:
                    # è§£æJSONæ•°æ®
                    data = json.loads(line)
                    
                    # è§£ææ¶ˆæ¯
                    parsed = parse_historical_message(data)
                    
                    if parsed:
                        # å­˜å‚¨åˆ°æ•°æ®åº“
                        result = upsert_historical_message(session, parsed)
                        processed += 1
                        
                        if result == 'inserted':
                            inserted += 1
                        elif result == 'updated':
                            updated += 1
                        else:
                            skipped += 1
                        
                        # æ¯å¤„ç†100æ¡è®°å½•æ˜¾ç¤ºè¿›åº¦
                        if processed % 100 == 0:
                            print(f"ğŸ“Š å·²å¤„ç† {processed} æ¡è®°å½• (æ’å…¥: {inserted}, æ›´æ–°: {updated}, è·³è¿‡: {skipped})")
                        
                        # æ¯1000æ¡è®°å½•é‡æ–°è¿æ¥æ•°æ®åº“
                        if processed % 1000 == 0:
                            try:
                                session.close()
                                session = create_db_session_with_retry()
                                print(f"ğŸ”„ é‡æ–°è¿æ¥æ•°æ®åº“ (ç¬¬ {processed} æ¡è®°å½•)")
                            except Exception as e:
                                print(f"âŒ é‡æ–°è¿æ¥å¤±è´¥: {e}")
                                break
                    
                except json.JSONDecodeError as e:
                    print(f"âŒ ç¬¬ {line_num} è¡ŒJSONè§£æé”™è¯¯: {e}")
                    continue
                except Exception as e:
                    print(f"âŒ ç¬¬ {line_num} è¡Œå¤„ç†é”™è¯¯: {e}")
                    continue
        
        print(f"\nâœ… å¯¼å…¥å®Œæˆ!")
        print(f"ğŸ“Š æ€»è®¡å¤„ç†: {total_lines} è¡Œ")
        print(f"ğŸ“Š æœ‰æ•ˆæ¶ˆæ¯: {processed} æ¡")
        print(f"ğŸ“Š æ–°å¢æ¶ˆæ¯: {inserted} æ¡")
        print(f"ğŸ“Š æ›´æ–°æ¶ˆæ¯: {updated} æ¡")
        print(f"ğŸ“Š è·³è¿‡æ¶ˆæ¯: {skipped} æ¡")
        
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        if session:
            session.rollback()
    finally:
        if session:
            session.close()

if __name__ == "__main__":
    main()