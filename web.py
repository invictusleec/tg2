import streamlit as st
from sqlalchemy.orm import Session
from model import Message, engine
import pandas as pd
from datetime import datetime, timedelta, timezone
from collections import Counter
from sqlalchemy import or_, cast, String
import json
import os

# åˆå§‹åŒ–session_stateç”¨äºæ ‡ç­¾ç­›é€‰
if 'selected_tags' not in st.session_state:
    st.session_state['selected_tags'] = []

st.set_page_config(
    page_title="TGé¢‘é“ç›‘æ§",
    page_icon="ğŸ“±",
    layout="wide"
)

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.title("ğŸ“± TGé¢‘é“ç›‘æ§")

# åˆ›å»ºä¾§è¾¹æ 
st.sidebar.header("ç­›é€‰æ¡ä»¶")

# æ—¶é—´èŒƒå›´é€‰æ‹©
time_range = st.sidebar.selectbox(
    "æ—¶é—´èŒƒå›´",
    ["æœ€è¿‘24å°æ—¶", "æœ€è¿‘7å¤©", "æœ€è¿‘30å¤©", "å…¨éƒ¨"]
)

# æ ‡ç­¾é€‰æ‹©ï¼ˆæ ‡ç­¾äº‘ï¼Œæ˜¾ç¤ºæ•°é‡ï¼Œé™åºï¼‰
@st.cache_data(ttl=300)
def get_tag_data():
    with Session(engine) as session:
        all_tags = session.query(Message.tags).all()
    tag_list = [tag for tags in all_tags for tag in (tags[0] if tags[0] else [])]
    tag_counter = Counter(tag_list)
    tag_items = sorted(tag_counter.items(), key=lambda x: x[1], reverse=True)
    tag_options = [f"{tag} ({count})" for tag, count in tag_items]
    tag_map = {f"{tag} ({count})": tag for tag, count in tag_items}
    return tag_options, tag_map, {tag: count for tag, count in tag_items}

try:
    tag_options, tag_map, tag_counter = get_tag_data()
except Exception:
    tag_options, tag_map, tag_counter = [], {}, {}

# é»˜è®¤é€‰ä¸­session_stateä¸­çš„æ ‡ç­¾
selected_tag_labels = st.sidebar.multiselect(
    "æ ‡ç­¾", tag_options,
    default=[f"{tag} ({tag_counter[tag]})" for tag in st.session_state['selected_tags'] if tag in tag_counter]
)
selected_tags = [tag_map[label] for label in selected_tag_labels]
# åŒæ­¥session_state
st.session_state['selected_tags'] = selected_tags

# ç½‘ç›˜ç±»å‹ç­›é€‰ï¼ˆåŸºäºå®é™…æ•°æ®åº“ä¸­çš„ç±»å‹ï¼‰
netdisk_types = ['å¤¸å…‹ç½‘ç›˜', 'ç™¾åº¦ç½‘ç›˜', 'é˜¿é‡Œäº‘ç›˜', 'è¿…é›·ç½‘ç›˜', 'UCç½‘ç›˜', '115ç½‘ç›˜', '123ç½‘ç›˜', 'å¤©ç¿¼äº‘ç›˜', 'ç§»åŠ¨äº‘ç›˜']
selected_netdisks = st.sidebar.multiselect("ç½‘ç›˜ç±»å‹", netdisk_types)

# å…³é”®è¯æ¨¡ç³Šæœç´¢ï¼ˆå¸¦æœç´¢æŒ‰é’®ï¼‰
if 'search_query' not in st.session_state:
    st.session_state['search_query'] = ''
_search_input = st.sidebar.text_input(
    "å…³é”®è¯æœç´¢",
    value=st.session_state['search_query'],
    placeholder="æ ‡é¢˜/æè¿°/é¢‘é“ æ¨¡ç³ŠåŒ¹é…",
    key='kw_input'
)
col_sa, col_sb = st.sidebar.columns([1, 1])
with col_sa:
    if st.button("æœç´¢", key="do_search"):
        st.session_state['search_query'] = _search_input.strip()
        st.session_state['page_num'] = 1
        st.rerun()
with col_sb:
    if st.button("æ¸…ç©º", key="clear_search"):
        st.session_state['search_query'] = ''
        st.session_state['page_num'] = 1
        st.rerun()
if st.session_state.get('search_query'):
    st.sidebar.caption(f"å½“å‰æœç´¢ï¼š{st.session_state['search_query']}")

# åˆ†é¡µå‚æ•°
PAGE_SIZE = 50
if 'page_num' not in st.session_state:
    st.session_state['page_num'] = 1
page_num = st.session_state['page_num']

# æ„å»ºæŸ¥è¯¢ï¼ˆæœåŠ¡ç«¯åˆ†é¡µ + SQLç«¯è¿‡æ»¤ï¼‰
with Session(engine) as session:
    query = session.query(Message)
    # åº”ç”¨æ—¶é—´èŒƒå›´è¿‡æ»¤
    if time_range == "æœ€è¿‘24å°æ—¶":
        query = query.filter(Message.timestamp >= datetime.now() - timedelta(days=1))
    elif time_range == "æœ€è¿‘7å¤©":
        query = query.filter(Message.timestamp >= datetime.now() - timedelta(days=7))
    elif time_range == "æœ€è¿‘30å¤©":
        query = query.filter(Message.timestamp >= datetime.now() - timedelta(days=30))

    # ä»…å±•ç¤ºåŒ…å«ç™½åå•ç½‘ç›˜é“¾æ¥çš„æ¶ˆæ¯ï¼ˆSQL ç«¯ç²—è¿‡æ»¤ + JSON ä¸²åŒ¹é…ï¼‰
    whitelist_like = or_(
        cast(Message.links, String).ilike('%pan.baidu.com/s/%'),
        cast(Message.links, String).ilike('%pan.quark.cn/s/%'),
        cast(Message.links, String).ilike('%aliyundrive.com/s/%'),
        cast(Message.links, String).ilike('%115.com/s/%'),
        cast(Message.links, String).ilike('%pan.xunlei.com/s/%'),
        cast(Message.links, String).ilike('%drive.uc.cn/s/%'),
        cast(Message.links, String).ilike('%www.123pan.com/s/%'),
        cast(Message.links, String).ilike('%www.123684.com/s/%'),
        cast(Message.links, String).ilike('%cloud.189.cn/t/%'),
        cast(Message.links, String).ilike('%caiyun.139.com/w/i/%'),
    )
    query = query.filter(Message.links.isnot(None)).filter(whitelist_like)

    # åº”ç”¨æ ‡ç­¾è¿‡æ»¤
    if selected_tags:
        filters = [Message.tags.any(tag) for tag in selected_tags]
        query = query.filter(or_(*filters))
    # åº”ç”¨å…³é”®è¯æ¨¡ç³Šæœç´¢ï¼ˆAND ç»„åˆå¤šå…³é”®è¯ï¼ŒOR åŒ¹é…å¤šä¸ªå­—æ®µï¼‰
    _q = st.session_state.get('search_query', '').strip()
    if _q:
        kws = [k for k in _q.split() if k]
        for kw in kws:
            pattern = f"%{kw}%"
            query = query.filter(
                or_(
                    Message.title.ilike(pattern),
                    Message.description.ilike(pattern),
                    Message.channel.ilike(pattern),
                    Message.source.ilike(pattern),
                )
            )

    # ç½‘ç›˜ç±»å‹ç­›é€‰ä¼˜åŒ–ï¼šåªæœ‰é€‰æ‹©äº†ç½‘ç›˜ç±»å‹æ—¶æ‰ä½¿ç”¨Pythonè¿‡æ»¤
    if selected_netdisks:
        # å…ˆè·å–å½“å‰æ¡ä»¶ä¸‹çš„æ¶ˆæ¯è¿›è¡ŒPythonè¿‡æ»¤
        all_messages = query.order_by(Message.timestamp.desc()).all()
        
        filtered_messages = []
        for msg in all_messages:
            if isinstance(msg.links, dict) and any(nd in msg.links.keys() for nd in selected_netdisks):
                filtered_messages.append(msg)
        
        total_count = len(filtered_messages)
        max_page = (total_count + PAGE_SIZE - 1) // PAGE_SIZE if total_count else 1
        if page_num < 1:
            page_num = 1
        if page_num > max_page:
            page_num = max_page
            st.session_state['page_num'] = page_num
        
        start_idx = (page_num - 1) * PAGE_SIZE
        end_idx = start_idx + PAGE_SIZE
        messages_page = filtered_messages[start_idx:end_idx]
    else:
        total_count = query.order_by(None).count()
        max_page = (total_count + PAGE_SIZE - 1) // PAGE_SIZE if total_count else 1
        if page_num < 1:
            page_num = 1
        if page_num > max_page:
            page_num = max_page
            st.session_state['page_num'] = page_num
        
        start_idx = (page_num - 1) * PAGE_SIZE
        messages_page = query.order_by(Message.timestamp.desc()).offset(start_idx).limit(PAGE_SIZE).all()

# æ˜¾ç¤ºæ¶ˆæ¯åˆ—è¡¨ï¼ˆåˆ†é¡µåï¼‰
for msg in messages_page:
    # æ ‡é¢˜è¡Œä¿ç•™ç½‘ç›˜æ ‡ç­¾ï¼Œç”¨ç‰¹æ®Šç¬¦å·åŒºåˆ†
    if msg.links:
        netdisk_tags = " ".join([f"ğŸ”µ[{name}]" for name in msg.links.keys()])
    else:
        netdisk_tags = ""
    # æ•°æ®åº“ç°åœ¨å­˜å‚¨çš„æ˜¯åŒ—äº¬æ—¶é—´ï¼Œç›´æ¥ä½¿ç”¨å³å¯
    local_ts = msg.timestamp
    expander_title = f"{msg.title} - ğŸ•’{local_ts.strftime('%Y-%m-%d %H:%M:%S')}  {netdisk_tags}"
    with st.expander(expander_title):
        if msg.description:
            st.markdown(msg.description)
        if msg.links:
            link_str = " ".join([
                f"<a href='{link}' target='_blank'><span class='netdisk-tag'>{name}</span></a>"
                for name, link in msg.links.items()
            ])
            st.markdown(link_str, unsafe_allow_html=True)
        # æ¡ç›®æ ‡ç­¾æ ‡ç­¾åŒºï¼ˆä»…å±•ç¤ºï¼Œä¸å¯ç‚¹å‡»ï¼Œä¿ç•™æ ·å¼ï¼‰
        if msg.tags:
            tag_html = ""
            for tag in msg.tags:
                tag_html += f"<span class='tag-btn'>#{tag}</span>"
            st.markdown(tag_html, unsafe_allow_html=True)

# æ˜¾ç¤ºåˆ†é¡µä¿¡æ¯å’Œè·³è½¬æ§ä»¶ï¼ˆæŒ‰é’®å’Œé¡µç ä¿¡æ¯åŒä¸€è¡Œå±…ä¸­ï¼‰
if max_page > 1:
    col1, col2, col3 = st.columns([1,2,1])
    with col1:
        if st.button('ä¸Šä¸€é¡µ', disabled=page_num==1, key='prev_page'):
            st.session_state['page_num'] = max(1, page_num-1)
            st.rerun()
    with col2:
        st.markdown(f"<div style='text-align:center;line-height:38px;'>å…± {total_count} æ¡ï¼Œå½“å‰ç¬¬ {page_num} / {max_page} é¡µ</div>", unsafe_allow_html=True)
    with col3:
        if st.button('ä¸‹ä¸€é¡µ', disabled=page_num==max_page, key='next_page'):
            st.session_state['page_num'] = min(max_page, page_num+1)
            st.rerun()

# å¤„ç†ç‚¹å‡»æ¡ç›®æ ‡ç­¾ç­›é€‰
if 'tag_click' in st.session_state and st.session_state['tag_click']:
    tag = st.session_state['tag_click']
    if tag not in st.session_state['selected_tags']:
        st.session_state['selected_tags'].append(tag)
        st.session_state['tag_click'] = None
        st.rerun()
    st.session_state['tag_click'] = None

# æ·»åŠ è‡ªåŠ¨åˆ·æ–°ä¸è¯´æ˜
st.empty()
st.markdown("---")

# ä»é…ç½®æ–‡ä»¶è¯»å–åˆ·æ–°é—´éš”ï¼Œé»˜è®¤60ç§’
REFRESH_CONFIG = "refresh_config.json"

def get_refresh_interval(default: int = 60) -> int:
    try:
        if os.path.exists(REFRESH_CONFIG):
            with open(REFRESH_CONFIG, 'r', encoding='utf-8') as f:
                data = json.load(f)
                val = int(data.get('interval_sec', default))
                return max(10, min(3600, val))
    except Exception:
        pass
    return default

interval = get_refresh_interval()
st.markdown(f"é¡µé¢æ¯{interval}ç§’è‡ªåŠ¨åˆ·æ–°ä¸€æ¬¡")

# äº¤äº’æ— é˜»å¡åˆ·æ–°ï¼šå½“ç­›é€‰æˆ–åˆ†é¡µå˜åŒ–æ—¶ï¼Œè·³è¿‡sleepï¼Œç«‹å³å®Œæˆæœ¬æ¬¡æ¸²æŸ“
import hashlib as _hashlib

# ä»…ç”¨äºåˆ¤æ–­ç­›é€‰æ˜¯å¦å˜åŒ–ï¼ˆä¸å«åˆ†é¡µï¼‰ï¼Œå˜åŒ–æ—¶é‡ç½®åˆ°ç¬¬1é¡µ
_filter_state = {
    'time_range': time_range,
    'selected_tags': sorted(st.session_state.get('selected_tags', [])),
    'selected_netdisks': sorted(selected_netdisks),
    'search_query': st.session_state.get('search_query', ''),
}
_filter_sig = _hashlib.md5(json.dumps(_filter_state, ensure_ascii=False, sort_keys=True).encode('utf-8')).hexdigest()
_prev_filter_sig = st.session_state.get('filter_sig')
if _prev_filter_sig != _filter_sig:
    # ç­›é€‰æ¡ä»¶å‘ç”Ÿå˜åŒ–ï¼Œé‡ç½®åˆ†é¡µå¹¶è®°å½•ç­¾å
    st.session_state['page_num'] = 1
    st.session_state['filter_sig'] = _filter_sig
    # æœ¬æ¬¡ä¸ºäº¤äº’å˜æ›´ï¼Œç›´æ¥è¿”å›ï¼ˆä¸sleepï¼‰ï¼Œè®©ç•Œé¢ç«‹å³æ›´æ–°
    # æ³¨æ„ï¼šStreamlitä¼šåœ¨ä¸‹ä¸€æ¬¡ç©ºé—²æ¸²æŸ“æ—¶å†è¿›å…¥è‡ªåŠ¨åˆ·æ–°
else:
    # ç”¨äºåˆ¤æ–­äº¤äº’æ˜¯å¦å‘ç”Ÿï¼ˆå«åˆ†é¡µåœ¨å†…çš„ä»»ä½•å˜åŒ–ï¼‰ï¼Œå˜åŒ–æ—¶ä¸sleep
    _ui_state = {
        'time_range': time_range,
        'selected_tags': sorted(st.session_state.get('selected_tags', [])),
        'selected_netdisks': sorted(selected_netdisks),
        'page_num': st.session_state.get('page_num', 1),
        'search_query': st.session_state.get('search_query', ''),
    }
    _ui_sig = _hashlib.md5(json.dumps(_ui_state, ensure_ascii=False, sort_keys=True).encode('utf-8')).hexdigest()
    _prev_ui_sig = st.session_state.get('ui_sig')
    if _prev_ui_sig != _ui_sig:
        st.session_state['ui_sig'] = _ui_sig
        # æœ¬æ¬¡ä¸ºäº¤äº’å˜æ›´ï¼Œç›´æ¥è¿”å›ï¼ˆä¸sleepï¼‰
    else:
        # æ— äº¤äº’å‘ç”Ÿï¼Œè¿›å…¥è‡ªåŠ¨æ‹‰å–æ¨¡å¼ï¼šsleepåè‡ªåŠ¨é‡è·‘
        import time as _time
        _time.sleep(interval)
        st.rerun()

# æ·»åŠ å…¨å±€CSSï¼Œå¼ºåŠ›è¦†ç›–expanderå†…å®¹åŒºçš„gapï¼Œåªä¿ç•™ä¸€å¤„ï¼Œæ”¾åœ¨æ–‡ä»¶æœ€å
st.markdown("""
    <style>
    [data-testid=\"stExpander\"] [data-testid=\"stExpanderContent\"] {
        gap: 0.2rem !important;
    }
    div[data-testid=\"stExpanderContent\"] {
        gap: 0.2rem !important;
    }
    [data-testid=\"stExpander\"] * {
        gap: 0.2rem !important;
    }
    .netdisk-tag {
        display: inline-block;
        background: #e6f0fa;
        color: #409eff;
        border-radius: 12px;
        padding: 2px 10px;
        margin: 2px 4px 2px 0;
        font-size: 13px;
    }
    .tag-btn {
        border:1px solid #222;
        border-radius:8px;
        padding:4px 16px;
        margin:2px 6px 2px 0;
        font-size:15px;
        background:#fff;
        color:#222;
        display:inline-block;
        transition: background 0.2s, color 0.2s;
        cursor: default;
    }
    .tag-btn:hover {
        background: #fff;
        color: #222;
    }
    </style>
""", unsafe_allow_html=True)