import streamlit as st
from sqlalchemy.orm import Session
from model import Message, engine
import pandas as pd
from datetime import datetime, timedelta, timezone
from collections import Counter
from sqlalchemy import or_, cast, String
from sqlalchemy.exc import OperationalError
import json
import os
import math

# ç»Ÿä¸€åœ¨é¡¶éƒ¨å®šä¹‰åˆ†é¡µå¤§å°ï¼Œä¾›åç»­å‡½æ•°é»˜è®¤å‚æ•°ä½¿ç”¨
PAGE_SIZE = 50

# åˆå§‹åŒ–session_stateç”¨äºæ ‡ç­¾ç­›é€‰
if 'selected_tags' not in st.session_state:
    st.session_state['selected_tags'] = []

st.set_page_config(
    page_title="ğŸ“± TGé¢‘é“ç›‘æ§",
    page_icon="ğŸ“±",
    layout="wide"
)

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.title("ğŸ“± TGé¢‘é“ç›‘æ§")

# åˆ›å»ºä¾§è¾¹æ 
st.sidebar.header("ç­›é€‰æ¡ä»¶")

# æ—¶é—´èŒƒå›´é€‰æ‹©
time_range = st.sidebar.selectbox(
    "æ—¶é—´èŒƒå›´",
    ["æœ€è¿‘24å°æ—¶", "æœ€è¿‘7å¤©", "æœ€è¿‘30å¤©", "å…¨éƒ¨"]
)

# æ ‡ç­¾é€‰æ‹©ï¼ˆæ ‡ç­¾äº‘ï¼Œæ˜¾ç¤ºæ•°é‡ï¼Œé™åºï¼‰
@st.cache_data(ttl=300)
def get_tag_data():
    try:
        with Session(engine) as session:
            cutoff = datetime.now() - timedelta(days=90)
            all_tags = (
                session.query(Message.tags)
                .filter(Message.timestamp >= cutoff)
                .limit(200000)
                .all()
            )
    except OperationalError:
        engine.dispose()
        try:
            with Session(engine) as session:
                cutoff = datetime.now() - timedelta(days=90)
                all_tags = (
                    session.query(Message.tags)
                    .filter(Message.timestamp >= cutoff)
                    .limit(200000)
                    .all()
                )
        except Exception:
            all_tags = []
    tag_list = [tag for tags in all_tags for tag in (tags[0] if tags[0] else [])]
    tag_counter = Counter(tag_list)
    tag_items = sorted(tag_counter.items(), key=lambda x: x[1], reverse=True)
    tag_options = [f"{tag} ({count})" for tag, count in tag_items]
    tag_map = {f"{tag} ({count})": tag for tag, count in tag_items}
    return tag_options, tag_map, {tag: count for tag, count in tag_items}

try:
    tag_options, tag_map, tag_counter = get_tag_data()
except Exception:
    tag_options, tag_map, tag_counter = [], {}, {}

# é»˜è®¤é€‰ä¸­session_stateä¸­çš„æ ‡ç­¾
selected_tag_labels = st.sidebar.multiselect(
    "æ ‡ç­¾", tag_options,
    default=[f"{tag} ({tag_counter[tag]})" for tag in st.session_state['selected_tags'] if tag in tag_counter]
)
selected_tags = [tag_map[label] for label in selected_tag_labels]
# åŒæ­¥session_state
st.session_state['selected_tags'] = selected_tags

# åŠ¨æ€è·å–ç½‘ç›˜ç±»å‹ï¼ˆè¿‘90å¤©ï¼Œå¸¦è®¡æ•°ï¼‰ï¼Œå¹¶å…è®¸å¤šé€‰
@st.cache_data(ttl=300)
def get_netdisk_data():
    try:
        with Session(engine) as session:
            cutoff = datetime.now() - timedelta(days=90)
            rows = (
                session.query(Message.links)
                .filter(Message.timestamp >= cutoff)
                .limit(200000)
                .all()
            )
    except OperationalError:
        engine.dispose()
        try:
            with Session(engine) as session:
                cutoff = datetime.now() - timedelta(days=90)
                rows = (
                    session.query(Message.links)
                    .filter(Message.timestamp >= cutoff)
                    .limit(200000)
                    .all()
                )
        except Exception:
            rows = []
    keys = []
    for r in rows:
        links = r[0] if r else None
        if isinstance(links, dict):
            keys.extend(list(links.keys()))
    counter = Counter(keys)
    items = sorted(counter.items(), key=lambda x: x[1], reverse=True)
    options = [f"{k} ({v})" for k, v in items]
    key_map = {f"{k} ({v})": k for k, v in items}
    return options, key_map, {k: v for k, v in items}

try:
    netdisk_options, netdisk_map, netdisk_counter = get_netdisk_data()
except Exception:
    netdisk_options, netdisk_map, netdisk_counter = [], {}, {}

if 'selected_netdisks' not in st.session_state:
    st.session_state['selected_netdisks'] = []
selected_nd_labels = st.sidebar.multiselect(
    "ç½‘ç›˜ç±»å‹", netdisk_options,
    default=[f"{nd} ({netdisk_counter[nd]})" for nd in st.session_state['selected_netdisks'] if nd in netdisk_counter]
)
selected_netdisks = [netdisk_map[label] for label in selected_nd_labels]
# åŒæ­¥session_state
st.session_state['selected_netdisks'] = selected_netdisks

# å…³é”®è¯æ¨¡ç³Šæœç´¢ï¼ˆå¸¦æœç´¢æŒ‰é’®ï¼‰
if 'search_query' not in st.session_state:
    st.session_state['search_query'] = ''
_search_input = st.sidebar.text_input(
    "å…³é”®è¯æœç´¢",
    value=st.session_state['search_query'],
    placeholder="æ ‡é¢˜/æè¿°/é¢‘é“ æ¨¡ç³ŠåŒ¹é…",
    key='kw_input'
)
col_sa, col_sb = st.sidebar.columns([1, 1])
with col_sa:
    if st.button("æœç´¢", key="do_search"):
        st.session_state['search_query'] = _search_input.strip()
        st.session_state['page_num'] = 1
        st.rerun()
with col_sb:
    if st.button("æ¸…ç©º", key="clear_search"):
        st.session_state['search_query'] = ''
        st.session_state['page_num'] = 1
        st.rerun()
if st.session_state.get('search_query'):
    st.sidebar.caption(f"å½“å‰æœç´¢ï¼š{st.session_state['search_query']}")

# åœ¨æ—¶é—´èŒƒå›´é€‰æ‹©ä¸‹æ–¹å±•ç¤ºâ€œæŒ‰æ—¶é—´èŒƒå›´ä¼°ç®—æ€»é¡µæ•°/æ€»æ¡æ•°â€ï¼ˆå¿½ç•¥æ ‡ç­¾/ç½‘ç›˜/å…³é”®è¯è¿‡æ»¤ï¼Œä»…åŸºäºæ—¶é—´ä¸ç™½åå•ï¼‰
@st.cache_data(ttl=60)
def estimate_total_pages_by_time_range(_time_range: str, page_size: int = PAGE_SIZE):
    def _apply_time_filter(q):
        if _time_range == "æœ€è¿‘24å°æ—¶":
            return q.filter(Message.timestamp >= datetime.now() - timedelta(days=1))
        elif _time_range == "æœ€è¿‘7å¤©":
            return q.filter(Message.timestamp >= datetime.now() - timedelta(days=7))
        elif _time_range == "æœ€è¿‘30å¤©":
            return q.filter(Message.timestamp >= datetime.now() - timedelta(days=30))
        return q
    whitelist_like_local = or_(
        cast(Message.links, String).ilike('%pan.baidu.com/s/%'),
        cast(Message.links, String).ilike('%pan.quark.cn/s/%'),
        cast(Message.links, String).ilike('%aliyundrive.com/s/%'),
        cast(Message.links, String).ilike('%115.com/s/%'),
        cast(Message.links, String).ilike('%pan.xunlei.com/s/%'),
        cast(Message.links, String).ilike('%drive.uc.cn/s/%'),
        cast(Message.links, String).ilike('%www.123pan.com/s/%'),
        cast(Message.links, String).ilike('%www.123684.com/s/%'),
        cast(Message.links, String).ilike('%cloud.189.cn/t/%'),
        cast(Message.links, String).ilike('%caiyun.139.com/w/i/%'),
    )
    try:
        with Session(engine) as session:
            base = session.query(Message.id)
            base = _apply_time_filter(base)
            base = base.filter(Message.links.isnot(None)).filter(whitelist_like_local)
            total_count = base.count()
    except OperationalError:
        engine.dispose()
        try:
            with Session(engine) as session:
                base = session.query(Message.id)
                base = _apply_time_filter(base)
                base = base.filter(Message.links.isnot(None)).filter(whitelist_like_local)
                total_count = base.count()
        except Exception:
            return None, None
    pages = max(1, math.ceil(total_count / page_size)) if total_count else 1
    return total_count, pages

_total_count, _total_pages = estimate_total_pages_by_time_range(time_range, PAGE_SIZE)
if _total_count is not None:
    st.sidebar.caption(f"æŒ‰æ—¶é—´èŒƒå›´ä¼°ç®—ï¼šå…± {_total_count} æ¡ï¼Œçº¦ {_total_pages} é¡µ")
else:
    st.sidebar.caption("æŒ‰æ—¶é—´èŒƒå›´ä¼°ç®—æ€»é¡µæ•°ï¼šæš‚ä¸å¯ç”¨")

# åˆ†é¡µå‚æ•°ï¼ˆç§»é™¤é‡å¤å®šä¹‰ï¼Œä»…ä¿ç•™é¡µç çŠ¶æ€ï¼‰
if 'page_num' not in st.session_state:
    st.session_state['page_num'] = 1
page_num = st.session_state['page_num']

# æ„å»ºæŸ¥è¯¢ï¼ˆæœåŠ¡ç«¯åˆ†é¡µ + SQLç«¯è¿‡æ»¤ï¼‰
with Session(engine) as session:
    query = session.query(Message)
    # åº”ç”¨æ—¶é—´èŒƒå›´è¿‡æ»¤
    if time_range == "æœ€è¿‘24å°æ—¶":
        query = query.filter(Message.timestamp >= datetime.now() - timedelta(days=1))
    elif time_range == "æœ€è¿‘7å¤©":
        query = query.filter(Message.timestamp >= datetime.now() - timedelta(days=7))
    elif time_range == "æœ€è¿‘30å¤©":
        query = query.filter(Message.timestamp >= datetime.now() - timedelta(days=30))

    # ä»…å±•ç¤ºåŒ…å«ç™½åå•ç½‘ç›˜é“¾æ¥çš„æ¶ˆæ¯ï¼ˆSQL ç«¯ç²—è¿‡æ»¤ + JSON ä¸²åŒ¹é…ï¼‰
    whitelist_like = or_(
        cast(Message.links, String).ilike('%pan.baidu.com/s/%'),
        cast(Message.links, String).ilike('%pan.quark.cn/s/%'),
        cast(Message.links, String).ilike('%aliyundrive.com/s/%'),
        cast(Message.links, String).ilike('%115.com/s/%'),
        cast(Message.links, String).ilike('%pan.xunlei.com/s/%'),
        cast(Message.links, String).ilike('%drive.uc.cn/s/%'),
        cast(Message.links, String).ilike('%www.123pan.com/s/%'),
        cast(Message.links, String).ilike('%www.123684.com/s/%'),
        cast(Message.links, String).ilike('%cloud.189.cn/t/%'),
        cast(Message.links, String).ilike('%caiyun.139.com/w/i/%'),
    )
    query = query.filter(Message.links.isnot(None)).filter(whitelist_like)

    # åº”ç”¨æ ‡ç­¾è¿‡æ»¤
    if selected_tags:
        filters = [Message.tags.any(tag) for tag in selected_tags]
        query = query.filter(or_(*filters))
    # åº”ç”¨å…³é”®è¯æ¨¡ç³Šæœç´¢ï¼ˆAND ç»„åˆå¤šå…³é”®è¯ï¼ŒOR åŒ¹é…å¤šä¸ªå­—æ®µï¼‰
    _q = st.session_state.get('search_query', '').strip()
    if _q:
        kws = [k for k in _q.split() if k]
        for kw in kws:
            pattern = f"%{kw}%"
            query = query.filter(
                or_(
                    Message.title.ilike(pattern),
                    Message.description.ilike(pattern),
                    Message.channel.ilike(pattern),
                    Message.source.ilike(pattern),
                )
            )

    # ç½‘ç›˜ç±»å‹ï¼šå°†ç­›é€‰æ¡ä»¶ä¸‹æ¨åˆ° SQLï¼ˆé¿å… Python ä¾§å…¨é‡å–æ•°ï¼‰
    if selected_netdisks:
        # å…¼å®¹ä¸åŒæ¥æºçš„ç½‘ç›˜ç±»å‹åç§°ï¼Œä¼˜å…ˆä½¿ç”¨åŸŸåæ¨¡å¼åŒ¹é…
        type_patterns = {
            'å¤¸å…‹ç½‘ç›˜': ['%pan.quark.cn/s/%'],
            'ç™¾åº¦ç½‘ç›˜': ['%pan.baidu.com/s/%'],
            'é˜¿é‡Œäº‘ç›˜': ['%aliyundrive.com/s/%', '%www.aliyundrive.com/s/%', '%www.alipan.com/s/%', '%alipan.com/s/%'],
            'è¿…é›·ç½‘ç›˜': ['%pan.xunlei.com/s/%'],
            'UCç½‘ç›˜': ['%drive.uc.cn/s/%'],
            '115ç½‘ç›˜': ['%115.com/s/%'],
            '123ç½‘ç›˜': ['%www.123pan.com/s/%', '%www.123684.com/s/%'],
            'å¤©ç¿¼äº‘ç›˜': ['%cloud.189.cn/t/%'],
            'ç§»åŠ¨äº‘ç›˜': ['%caiyun.139.com/w/i/%'],
        }
        nd_filters = []
        for nd in selected_netdisks:
            pats = type_patterns.get(nd, [])
            if pats:
                nd_filters.append(or_(*[cast(Message.links, String).ilike(p) for p in pats]))
            # é¢å¤–å¢åŠ å¯¹ JSON æ–‡æœ¬åŒ…å«ä¸­æ–‡é”®åçš„å…œåº•åŒ¹é…
            nd_filters.append(cast(Message.links, String).ilike(f"%{nd}%"))
        query = query.filter(or_(*nd_filters))

    # åŸºäº LIMIT+1 çš„åˆ†é¡µï¼Œé¿å…æ˜‚è´µçš„ count()
    if page_num < 1:
        page_num = 1
        st.session_state['page_num'] = 1
    start_idx = (page_num - 1) * PAGE_SIZE
    try:
        rows = (
            query.order_by(Message.timestamp.desc())
            .offset(start_idx)
            .limit(PAGE_SIZE + 1)
            .all()
        )
    except OperationalError:
        engine.dispose()
        rows = []
    has_next = len(rows) > PAGE_SIZE
    messages_page = rows[:PAGE_SIZE]

# æ˜¾ç¤ºæ¶ˆæ¯åˆ—è¡¨ï¼ˆåˆ†é¡µåï¼‰
for msg in messages_page:
    # æ ‡é¢˜è¡Œä¿ç•™ç½‘ç›˜æ ‡ç­¾ï¼Œç”¨ç‰¹æ®Šç¬¦å·åŒºåˆ†
    if msg.links:
        netdisk_tags = " ".join([f"ğŸ”µ[{name}]" for name in msg.links.keys()])
    else:
        netdisk_tags = ""
    # æ•°æ®åº“ç°åœ¨å­˜å‚¨çš„æ˜¯åŒ—äº¬æ—¶é—´ï¼Œç›´æ¥ä½¿ç”¨å³å¯
    local_ts = msg.timestamp
    expander_title = f"{msg.title} - ğŸ•’{local_ts.strftime('%Y-%m-%d %H:%M:%S')}  {netdisk_tags}"
    with st.expander(expander_title):
        if msg.description:
            st.markdown(msg.description)
        if msg.links:
            link_str = " ".join([
                f"<a href='{link}' target='_blank'><span class='netdisk-tag'>{name}</span></a>"
                for name, link in msg.links.items()
            ])
            st.markdown(link_str, unsafe_allow_html=True)
        # æ¡ç›®æ ‡ç­¾æ ‡ç­¾åŒºï¼ˆä»…å±•ç¤ºï¼Œä¸å¯ç‚¹å‡»ï¼Œä¿ç•™æ ·å¼ï¼‰
        if msg.tags:
            tag_html = ""
            for tag in msg.tags:
                tag_html += f"<span class='tag-btn'>#{tag}</span>"
            st.markdown(tag_html, unsafe_allow_html=True)

# æ˜¾ç¤ºåˆ†é¡µä¿¡æ¯å’Œè·³è½¬æ§ä»¶ï¼ˆæŒ‰é’®å’Œé¡µç ä¿¡æ¯åŒä¸€è¡Œå±…ä¸­ï¼‰
col1, col2, col3 = st.columns([1,2,1])
with col1:
    if st.button('ä¸Šä¸€é¡µ', disabled=page_num==1, key='prev_page'):
        st.session_state['page_num'] = max(1, page_num-1)
        st.rerun()
with col2:
    hint = "ï¼ˆå·²åˆ°æœ€åä¸€é¡µï¼‰" if not has_next else ""
    extra = f" / çº¦ {_total_pages} é¡µï¼ˆæŒ‰æ—¶é—´èŒƒå›´ï¼‰" if _total_pages else ""
    st.markdown(f"<div style='text-align:center;line-height:38px;'>å½“å‰ç¬¬ {page_num} é¡µ {hint}{extra}</div>", unsafe_allow_html=True)
with col3:
    if st.button('ä¸‹ä¸€é¡µ', disabled=(not has_next), key='next_page'):
        st.session_state['page_num'] = page_num + 1
        st.rerun()

# å¤„ç†ç‚¹å‡»æ¡ç›®æ ‡ç­¾ç­›é€‰
if 'tag_click' in st.session_state and st.session_state['tag_click']:
    tag = st.session_state['tag_click']
    if tag not in st.session_state['selected_tags']:
        st.session_state['selected_tags'].append(tag)
        st.session_state['tag_click'] = None
        st.rerun()
    st.session_state['tag_click'] = None

# æ·»åŠ è‡ªåŠ¨åˆ·æ–°ä¸è¯´æ˜
st.empty()

# --- ä»¥ä¸‹ä¿æŒä¸å˜ï¼šè‡ªåŠ¨åˆ·æ–°ä¸ CSS ---
st.markdown("---")

REFRESH_CONFIG = "refresh_config.json"

def get_refresh_interval(default: int = 60) -> int:
    try:
        if os.path.exists(REFRESH_CONFIG):
            with open(REFRESH_CONFIG, 'r', encoding='utf-8') as f:
                data = json.load(f)
                val = int(data.get('interval_sec', default))
                return max(10, min(3600, val))
    except Exception:
        pass
    return default

interval = get_refresh_interval()
st.markdown(f"é¡µé¢æ¯{interval}ç§’è‡ªåŠ¨åˆ·æ–°ä¸€æ¬¡")

import hashlib as _hashlib

_filter_state = {
    'time_range': time_range,
    'selected_tags': sorted(st.session_state.get('selected_tags', [])),
    'selected_netdisks': sorted(st.session_state.get('selected_netdisks', [])),
    'search_query': st.session_state.get('search_query', ''),
}
_filter_sig = _hashlib.md5(json.dumps(_filter_state, ensure_ascii=False, sort_keys=True).encode('utf-8')).hexdigest()
_prev_filter_sig = st.session_state.get('filter_sig')
if _prev_filter_sig != _filter_sig:
    st.session_state['page_num'] = 1
    st.session_state['filter_sig'] = _filter_sig
else:
    _ui_state = {
        'time_range': time_range,
        'selected_tags': sorted(st.session_state.get('selected_tags', [])),
        'selected_netdisks': sorted(st.session_state.get('selected_netdisks', [])),
        'page_num': st.session_state.get('page_num', 1),
        'search_query': st.session_state.get('search_query', ''),
    }
    _ui_sig = _hashlib.md5(json.dumps(_ui_state, ensure_ascii=False, sort_keys=True).encode('utf-8')).hexdigest()
    _prev_ui_sig = st.session_state.get('ui_sig')
    if _prev_ui_sig != _ui_sig:
        st.session_state['ui_sig'] = _ui_sig
    else:
        import time as _time
        _time.sleep(interval)
        st.rerun()

st.markdown(
    """
    <style>
    .tag-btn { display:inline-block; margin: 2px 6px 2px 0; padding: 2px 8px; background:#f1f5f9; border-radius: 12px; color:#0f172a; font-size:12px; }
    .netdisk-tag { display:inline-block; margin: 2px 6px 2px 0; padding: 2px 8px; background:#ecfeff; border-radius: 12px; color:#155e75; font-size:12px; border:1px solid #a5f3fc; }
    </style>
    """,
    unsafe_allow_html=True,
)